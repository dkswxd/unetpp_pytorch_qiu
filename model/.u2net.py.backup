import re
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.utils.checkpoint as cp
from collections import OrderedDict
from torch import Tensor
from torch.jit.annotations import List

class u2net(nn.Module):
    def __init__(self, config):
        super(u2net, self).__init__()
        self.layers = config['layers']
        self.feature_root = config['feature_root']
        self.channels = config['channels']
        self.n_class = config['n_class']
        # self.use_bn = config['use_bn']
        self.track_running_stats = config['track_running_stats']
        # self.bn_momentum = config['bn_momentum']
        # self.use_nonlocal = config['use_nonlocal']
        # self.conv_repeat = config['conv_repeat']
        self.u2net_type = config['u2net_type']


        fr = self.feature_root
        ch = self.channels
        nc = self.n_class
        if self.u2net_type == "full": # dict, in_channel, middle_channel, out_channel
            self.en_1 = RSU( 7, ch *  1, fr * 1, fr *  2, self.track_running_stats, 'none')
            self.en_2 = RSU( 6, fr *  2, fr * 1, fr *  4, self.track_running_stats, 'down')
            self.en_3 = RSU( 5, fr *  4, fr * 2, fr *  8, self.track_running_stats, 'down')
            self.en_4 = RSU( 4, fr *  8, fr * 4, fr * 16, self.track_running_stats, 'down')
            self.en_5 = RSUF(4, fr * 16, fr * 8, fr * 16, self.track_running_stats, 'down')
            self.en_6 = RSUF(4, fr * 16, fr * 8, fr * 16, self.track_running_stats, 'down')
            self.de_5 = RSUF(4, fr * 32, fr * 8, fr * 16, self.track_running_stats, 'none')
            self.de_4 = RSU( 4, fr * 32, fr * 4, fr *  8, self.track_running_stats, 'none')
            self.de_3 = RSU( 5, fr * 16, fr * 2, fr *  4, self.track_running_stats, 'none')
            self.de_2 = RSU( 6, fr *  8, fr * 1, fr *  2, self.track_running_stats, 'none')
            self.de_1 = RSU( 7, fr *  4, fr / 2, fr *  2, self.track_running_stats, 'none')
            self.sup_6 = SUP(5, fr * 16, nc) #upsample_times, in_channel, out_channel
            self.sup_5 = SUP(4, fr * 16, nc)
            self.sup_4 = SUP(3, fr *  8, nc)
            self.sup_3 = SUP(2, fr *  4, nc)
            self.sup_2 = SUP(1, fr *  2, nc)
            self.sup_1 = SUP(0, fr *  2, nc)
            self.sup_0 = SUP(0, nc *  6, nc)
        elif self.u2net_type == "small":
            self.en_1 = RSU( 7, ch *  1, fr / 2, fr *  2, self.track_running_stats, 'none')
            self.en_2 = RSU( 6, fr *  2, fr / 2, fr *  2, self.track_running_stats, 'down')
            self.en_3 = RSU( 5, fr *  2, fr / 2, fr *  2, self.track_running_stats, 'down')
            self.en_4 = RSU( 4, fr *  2, fr / 2, fr *  2, self.track_running_stats, 'down')
            self.en_5 = RSUF(4, fr *  2, fr / 2, fr *  2, self.track_running_stats, 'down')
            self.en_6 = RSUF(4, fr *  2, fr / 2, fr *  2, self.track_running_stats, 'down')
            self.de_5 = RSUF(4, fr *  4, fr / 2, fr *  2, self.track_running_stats, 'none')
            self.de_4 = RSU( 4, fr *  4, fr / 2, fr *  2, self.track_running_stats, 'none')
            self.de_3 = RSU( 5, fr *  4, fr / 2, fr *  2, self.track_running_stats, 'none')
            self.de_2 = RSU( 6, fr *  4, fr / 2, fr *  2, self.track_running_stats, 'none')
            self.de_1 = RSU( 7, fr *  4, fr / 2, fr *  2, self.track_running_stats, 'none')
            self.sup_6 = SUP(5, fr *  2, nc)
            self.sup_5 = SUP(4, fr *  2, nc)
            self.sup_4 = SUP(3, fr *  2, nc)
            self.sup_3 = SUP(2, fr *  2, nc)
            self.sup_2 = SUP(1, fr *  2, nc)
            self.sup_1 = SUP(0, fr *  2, nc)
            self.sup_0 = SUP(0, nc *  6, nc)

        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.constant_(m.bias, 0)


    def forward(self, x):
        x_en_1 = self.en_1(x)
        x_en_2 = self.en_2(x_en_1)
        x_en_3 = self.en_3(x_en_2)
        x_en_4 = self.en_4(x_en_3)
        x_en_5 = self.en_5(x_en_4)
        x_en_6 = self.en_6(x_en_5)
        x_de_5 = self.de_5(torch.cat((F.interpolate(x_en_6,scale_factor=2), x_en_5), 1))
        x_de_4 = self.de_4(torch.cat((F.interpolate(x_de_5,scale_factor=2), x_en_4), 1))
        x_de_3 = self.de_3(torch.cat((F.interpolate(x_de_4,scale_factor=2), x_en_3), 1))
        x_de_2 = self.de_2(torch.cat((F.interpolate(x_de_3,scale_factor=2), x_en_2), 1))
        x_de_1 = self.de_1(torch.cat((F.interpolate(x_de_2,scale_factor=2), x_en_1), 1))
        pred_6 = self.sup_6(x_en_6)
        pred_5 = self.sup_5(x_de_5)
        pred_4 = self.sup_4(x_de_4)
        pred_3 = self.sup_3(x_de_3)
        pred_2 = self.sup_2(x_de_2)
        pred_1 = self.sup_1(x_de_1)
        pred_0 = self.sup_0(torch.cat((pred_6, pred_5, pred_4, pred_3, pred_2, pred_1), 1))
        return [pred_6, pred_5, pred_4, pred_3, pred_2, pred_1, pred_0]

#############################################################################    RSU

class RSU(nn.Module):
    def __init__(self, layers, in_channel, middle_channel, out_channel, track_running_stats, scale_opertaion):
        super(RSU, self).__init__()
        self.layers = layers
        self.track_running_stats = track_running_stats
        middle_channel = int(middle_channel)
        if scale_opertaion == 'down':
            od = OrderedDict([('res_pool', nn.MaxPool2d(kernel_size=2))])
        elif scale_opertaion == 'up':
            od = OrderedDict([('res_upsa', nn.UpsamplingNearest2d(scale_factor=2))])
        else:
            od = OrderedDict()
        od.update(self.get_conv_block(in_channel, out_channel, 'res', 1, 1))
        self.res_w = nn.Sequential(od)

        self.down_sample_convs = torch.nn.ModuleDict()
        # down sample conv layers
        for layer in range(layers):
            if layer == 0:
                self.down_sample_convs['down{}'.format(layer)] = nn.Sequential(
                    self.get_conv_block(out_channel, middle_channel, 'down{}'.format(layer), 1, 1))
            elif layer == layers - 1:
                self.down_sample_convs['down{}'.format(layer)] = nn.Sequential(
                    self.get_conv_block(middle_channel, middle_channel, 'down{}'.format(layer), 2, 2))
            else:
                od = OrderedDict([('down{}_pool'.format(layer), nn.MaxPool2d(kernel_size=2))])
                od.update(self.get_conv_block(middle_channel, middle_channel, 'down{}'.format(layer), 1, 1))
                self.down_sample_convs['down{}'.format(layer)] = nn.Sequential(od)

        self.up_sample_convs = torch.nn.ModuleDict()
        # up sample conv layers
        for layer in range(layers - 2, -1, -1):
            if layer == 0:
                self.up_sample_convs['up{}'.format(layer)] = nn.Sequential(
                    self.get_conv_block(middle_channel * 2, out_channel, 'up{}'.format(layer), 1, 1))
            elif layer == layers - 2:
                self.up_sample_convs['up{}'.format(layer)] = nn.Sequential(
                    self.get_conv_block(middle_channel, middle_channel, 'up{}'.format(layer), 1, 1))
            else:
                self.up_sample_convs['up{}'.format(layer)] = nn.Sequential(
                    self.get_conv_block(middle_channel * 2, middle_channel, 'up{}'.format(layer), 1, 1))

        self.up_sample_transpose = torch.nn.ModuleDict()
        for layer in range(layers - 1, -1, -1):
            self.up_sample_transpose['up{}_transpose'.format(layer)] = nn.UpsamplingNearest2d(scale_factor=2)

        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.constant_(m.bias, 0)

    def forward(self, x):
        down_features = [self.res_w(x)]
        for layer in range(self.layers):
            down_features.append(self.down_sample_convs['down{}'.format(layer)](down_features[-1]))

        up_features = [self.up_sample_convs['up{}'.format(self.layers - 2)](down_features[-1])]
        for layer in range(self.layers - 3, -1, -1):
            _cat = torch.cat((down_features[layer + 1], self.up_sample_transpose['up{}_transpose'.format(layer)](up_features[-1])), 1)
            up_features.append(self.up_sample_convs['up{}'.format(layer)](_cat))
        result = up_features[-1] + down_features[0]
        return result

    def get_conv_block(self, in_feature, out_feature, prefix, dilation, padding):
        _return = OrderedDict([
                    (prefix+'_conv', nn.Conv2d(in_feature, out_feature, kernel_size=3, stride=1, dilation=dilation, padding=padding)),
                    (prefix+'_norm', nn.BatchNorm2d(out_feature, track_running_stats=self.track_running_stats)),
                    (prefix+'_relu', nn.ReLU(inplace=True)),
                    ])
        return _return


#############################################################################    RSUF

class RSUF(nn.Module):
    def __init__(self, layers, in_channel, middle_channel, out_channel, track_running_stats, scale_opertaion):
        super(RSUF, self).__init__()
        self.layers = layers
        self.in_channel = in_channel
        self.middle_channel = middle_channel
        self.out_channel = out_channel
        self.track_running_stats = track_running_stats
        middle_channel = int(middle_channel)
        if scale_opertaion == 'down':
            od = OrderedDict([('res_pool', nn.MaxPool2d(kernel_size=2))])
        elif scale_opertaion == 'up':
            od = OrderedDict([('res_upsa', nn.UpsamplingNearest2d(scale_factor=2))])
        else:
            od = OrderedDict()
        od.update(self.get_conv_block(in_channel, out_channel, 'res', 1, 1))
        self.res_w = nn.Sequential(od)

        self.down_sample_convs = torch.nn.ModuleDict()
        # down sample conv layers
        for layer in range(layers):
            if layer == 0:
                self.down_sample_convs['down{}'.format(layer)] = nn.Sequential(
                    self.get_conv_block(out_channel, middle_channel, 'down{}'.format(layer), 1, 1))
            else:
                self.down_sample_convs['down{}'.format(layer)] = nn.Sequential(
                    self.get_conv_block(middle_channel, middle_channel, 'down{}'.format(layer), 2 ** layer, 2 ** layer))

        self.up_sample_convs = torch.nn.ModuleDict()
        # up sample conv layers
        for layer in range(layers - 2, -1, -1):
            if layer == 0:
                self.up_sample_convs['up{}'.format(layer)] = nn.Sequential(
                    self.get_conv_block(middle_channel * 2, out_channel, 'up{}'.format(layer), 1, 1))
            elif layer == layers - 2:
                self.up_sample_convs['up{}'.format(layer)] = nn.Sequential(
                    self.get_conv_block(middle_channel, middle_channel, 'up{}'.format(layer), 1, 1))
            else:
                self.up_sample_convs['up{}'.format(layer)] = nn.Sequential(
                    self.get_conv_block(middle_channel * 2, middle_channel, 'up{}'.format(layer), 2 ** layer, 2 ** layer))

        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.constant_(m.bias, 0)

    def forward(self, x):
        down_features = [self.res_w(x)]
        for layer in range(self.layers):
            down_features.append(self.down_sample_convs['down{}'.format(layer)](down_features[-1]))

        up_features = [self.up_sample_convs['up{}'.format(self.layers - 2)](down_features[-1])]
        for layer in range(self.layers - 3, -1, -1):
            _cat = torch.cat((down_features[layer + 1], up_features[-1]),1)
            up_features.append(self.up_sample_convs['up{}'.format(layer)](_cat))
        result = up_features[-1] + down_features[0]
        return result

    def get_conv_block(self, in_feature, out_feature, prefix, dilation, padding):
        _return = OrderedDict([
            (prefix + '_conv', nn.Conv2d(in_feature, out_feature, kernel_size=3, stride=1, dilation=dilation, padding=padding)),
            (prefix + '_norm', nn.BatchNorm2d(out_feature, track_running_stats=self.track_running_stats)),
            (prefix + '_relu', nn.ReLU(inplace=True)),
        ])
        return _return

#############################################################################    RSUF

class SUP(nn.Module):
    def __init__(self, upsample_times, in_channel, out_channel):
        super(SUP, self).__init__()

        self.predict_layer = nn.Sequential(OrderedDict([
                ('predict_conv', nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=1, padding=1)),
                # ('predict_smax', nn.Sigmoid()),
                ('predict_smax', nn.Softmax2d()),
                ('predict_upsa', nn.UpsamplingNearest2d(scale_factor=2 ** upsample_times))
                ]))

        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.constant_(m.bias, 0)

    def forward(self, x):
        return self.predict_layer(x)
